{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3IIITtTXLdQ",
        "outputId": "4db4cf66-0f39-42a1-b4c9-14e2a51e9fec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images for selected 20 classes: 1988\n",
            "Train size: 1590, Test size: 398\n",
            "Remapped train dataset size: 1590\n",
            "Remapped test dataset size: 398\n",
            "Epoch [1/10], Loss: 56.4932, Accuracy: 63.71%\n",
            "Epoch [2/10], Loss: 27.3758, Accuracy: 82.45%\n",
            "Epoch [3/10], Loss: 17.8102, Accuracy: 88.87%\n",
            "Epoch [4/10], Loss: 10.1316, Accuracy: 93.77%\n",
            "Epoch [5/10], Loss: 7.8524, Accuracy: 94.97%\n",
            "Epoch [6/10], Loss: 9.3905, Accuracy: 94.53%\n",
            "Epoch [7/10], Loss: 8.0063, Accuracy: 94.59%\n",
            "Epoch [8/10], Loss: 7.1338, Accuracy: 95.85%\n",
            "Epoch [9/10], Loss: 5.2838, Accuracy: 97.30%\n",
            "Epoch [10/10], Loss: 7.0224, Accuracy: 95.53%\n",
            "Training completed and model saved as resnet20.pth\n",
            "Final Test Accuracy on 20-class dataset: 60.80%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models\n",
        "from torch.utils.data import DataLoader, Subset, random_split, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset = datasets.OxfordIIITPet(root='./data', split=\"trainval\", download=True, transform=transform)\n",
        "\n",
        "class_to_idx = dataset.class_to_idx\n",
        "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
        "\n",
        "np.random.seed(42)\n",
        "all_classes = np.array(list(class_to_idx.keys()))\n",
        "np.random.shuffle(all_classes)\n",
        "first_20_classes = all_classes[:20]\n",
        "first_20_list = [cls.lower() for cls in first_20_classes]\n",
        "\n",
        "selected_indices = [i for i, (img, label) in enumerate(dataset)\n",
        "                    if idx_to_class[label].lower() in first_20_list]\n",
        "print(f\"Total images for selected 20 classes: {len(selected_indices)}\")\n",
        "\n",
        "subset_20 = Subset(dataset, selected_indices)\n",
        "\n",
        "train_size = int(0.8 * len(subset_20))\n",
        "test_size = len(subset_20) - train_size\n",
        "train_subset, test_subset = random_split(subset_20, [train_size, test_size])\n",
        "print(f\"Train size: {train_size}, Test size: {test_size}\")\n",
        "\n",
        "def remap_labels(subset_obj):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for img, orig_label in subset_obj:\n",
        "        class_name = idx_to_class[orig_label].lower()\n",
        "        if class_name not in first_20_list:\n",
        "            print(\"Warning: unexpected class encountered:\", class_name)\n",
        "            continue\n",
        "        new_label = first_20_list.index(class_name)\n",
        "        images.append(img)\n",
        "        labels.append(new_label)\n",
        "    return torch.stack(images), torch.tensor(labels)\n",
        "\n",
        "train_images, train_labels = remap_labels(train_subset)\n",
        "test_images, test_labels = remap_labels(test_subset)\n",
        "\n",
        "print(f\"Remapped train dataset size: {len(train_labels)}\")\n",
        "print(f\"Remapped test dataset size: {len(test_labels)}\")\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(train_images, train_labels), batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(test_images, test_labels), batch_size=32, shuffle=False)\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 20)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), \"resnet20.pth\")\n",
        "print(\"Training completed and model saved as resnet20.pth\")\n",
        "\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_accuracy = 100 * correct / total\n",
        "print(f\"Final Test Accuracy on 20-class dataset: {test_accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part B**"
      ],
      "metadata": {
        "id": "iLAPzHST6rnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models\n",
        "from torch.utils.data import DataLoader, Subset, random_split, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset = datasets.OxfordIIITPet(root='./data', split=\"trainval\", download=True, transform=transform)\n",
        "\n",
        "class_to_idx = dataset.class_to_idx\n",
        "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
        "\n",
        "np.random.seed(42)\n",
        "all_classes = np.array(list(class_to_idx.keys()))\n",
        "np.random.shuffle(all_classes)\n",
        "first_20_classes = all_classes[:20]  # Old classes\n",
        "new_17_classes = all_classes[20:]  # New classes\n",
        "\n",
        "first_20_list = [cls.lower() for cls in first_20_classes]\n",
        "new_17_list = [cls.lower() for cls in new_17_classes]\n",
        "\n",
        "selected_indices_17 = [i for i, (img, label) in enumerate(dataset)\n",
        "                        if idx_to_class[label].lower() in new_17_list]\n",
        "print(f\"Total images for selected 17 classes: {len(selected_indices_17)}\")\n",
        "\n",
        "subset_17 = Subset(dataset, selected_indices_17)\n",
        "\n",
        "train_size_17 = int(0.8 * len(subset_17))\n",
        "test_size_17 = len(subset_17) - train_size_17\n",
        "train_subset_17, test_subset_17 = random_split(subset_17, [train_size_17, test_size_17])\n",
        "\n",
        "def remap_labels(subset_obj, class_list):\n",
        "    images, labels = [], []\n",
        "    for img, orig_label in subset_obj:\n",
        "        class_name = idx_to_class[orig_label].lower()\n",
        "        if class_name not in class_list:\n",
        "            print(\"Warning: unexpected class encountered:\", class_name)\n",
        "            continue\n",
        "        new_label = class_list.index(class_name)\n",
        "        images.append(img)\n",
        "        labels.append(new_label)\n",
        "    return torch.stack(images), torch.tensor(labels)\n",
        "\n",
        "train_images_17, train_labels_17 = remap_labels(train_subset_17, new_17_list)\n",
        "test_images_17, test_labels_17 = remap_labels(test_subset_17, new_17_list)\n",
        "\n",
        "print(f\"Remapped train dataset size (17 classes): {len(train_labels_17)}\")\n",
        "print(f\"Remapped test dataset size (17 classes): {len(test_labels_17)}\")\n",
        "\n",
        "train_loader_17 = DataLoader(TensorDataset(train_images_17, train_labels_17), batch_size=32, shuffle=True)\n",
        "test_loader_17 = DataLoader(TensorDataset(test_images_17, test_labels_17), batch_size=32, shuffle=False)\n",
        "\n",
        "model = models.resnet18(pretrained=False)\n",
        "model.fc = nn.Linear(model.fc.in_features, 20)\n",
        "model.load_state_dict(torch.load(\"resnet20.pth\"))\n",
        "model.to(device)\n",
        "\n",
        "# Modified FC layer for 37 classes\n",
        "model.fc = nn.Linear(model.fc.in_features, 37).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader_17:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), \"resnet37.pth\")\n",
        "print(\"Finetuning Completed. Model saved as resnet37.pth\")\n",
        "\n",
        "\n",
        "test_loader_37 = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "selected_indices_20 = [i for i, (img, label) in enumerate(dataset)\n",
        "                       if idx_to_class[label].lower() in first_20_list]\n",
        "test_subset_20 = Subset(dataset, selected_indices_20)\n",
        "\n",
        "test_images_20, test_labels_20 = remap_labels(test_subset_20, first_20_list)\n",
        "test_loader_20 = DataLoader(TensorDataset(test_images_20, test_labels_20), batch_size=32, shuffle=False)\n",
        "\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "accuracy_37 = evaluate_model(model, test_loader_37)\n",
        "accuracy_20 = evaluate_model(model, test_loader_20)\n",
        "accuracy_17 = evaluate_model(model, test_loader_17)\n",
        "\n",
        "print(f\"Final Test Accuracy on Full 37-class dataset: {accuracy_37:.2f}%\")\n",
        "print(f\"Accuracy on Original 20-class dataset: {accuracy_20:.2f}%\")\n",
        "print(f\"Accuracy on New 17-class dataset: {accuracy_17:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F29pWpXooj78",
        "outputId": "4edeb28b-cd73-4e69-a21c-802fb031658a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images for selected 17 classes: 1692\n",
            "Remapped train dataset size (17 classes): 1353\n",
            "Remapped test dataset size (17 classes): 339\n",
            "Epoch [1/10], Loss: 60.8314, Accuracy: 55.06%\n",
            "Epoch [2/10], Loss: 20.2399, Accuracy: 85.59%\n",
            "Epoch [3/10], Loss: 13.3732, Accuracy: 90.17%\n",
            "Epoch [4/10], Loss: 8.9782, Accuracy: 92.98%\n",
            "Epoch [5/10], Loss: 7.4219, Accuracy: 94.53%\n",
            "Epoch [6/10], Loss: 6.2730, Accuracy: 96.16%\n",
            "Epoch [7/10], Loss: 7.7627, Accuracy: 94.53%\n",
            "Epoch [8/10], Loss: 5.0917, Accuracy: 96.01%\n",
            "Epoch [9/10], Loss: 4.2363, Accuracy: 96.90%\n",
            "Epoch [10/10], Loss: 3.9222, Accuracy: 97.12%\n",
            "Finetuning Completed. Model saved as resnet37.pth\n",
            "Final Test Accuracy on Full 37-class dataset: 3.40%\n",
            "Accuracy on Original 20-class dataset: 4.38%\n",
            "Accuracy on New 17-class dataset: 70.21%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part C**"
      ],
      "metadata": {
        "id": "RyYDPgXc7G88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models\n",
        "from torch.utils.data import DataLoader, Subset, random_split, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset = datasets.OxfordIIITPet(root='./data', split=\"trainval\", download=True, transform=transform)\n",
        "\n",
        "class_to_idx = dataset.class_to_idx\n",
        "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
        "\n",
        "np.random.seed(42)\n",
        "all_classes = np.array(list(class_to_idx.keys()))\n",
        "np.random.shuffle(all_classes)\n",
        "first_20_classes = all_classes[:20]\n",
        "new_17_classes = all_classes[20:]\n",
        "\n",
        "first_20_list = [cls.lower() for cls in first_20_classes]\n",
        "new_17_list = [cls.lower() for cls in new_17_classes]\n",
        "\n",
        "selected_indices_20 = [i for i, (img, label) in enumerate(dataset)\n",
        "                        if idx_to_class[label].lower() in first_20_list]\n",
        "selected_indices_17 = [i for i, (img, label) in enumerate(dataset)\n",
        "                        if idx_to_class[label].lower() in new_17_list]\n",
        "\n",
        "old_subset_size = int(0.1 * len(selected_indices_20))\n",
        "np.random.shuffle(selected_indices_20)\n",
        "selected_indices_20_small = selected_indices_20[:old_subset_size]\n",
        "\n",
        "subset_17 = Subset(dataset, selected_indices_17)\n",
        "subset_20_small = Subset(dataset, selected_indices_20_small)\n",
        "\n",
        "train_size_17 = int(0.8 * len(subset_17))\n",
        "test_size_17 = len(subset_17) - train_size_17\n",
        "train_subset_17, test_subset_17 = random_split(subset_17, [train_size_17, test_size_17])\n",
        "\n",
        "def remap_labels(subset_obj, class_list):\n",
        "    images, labels = [], []\n",
        "    for img, orig_label in subset_obj:\n",
        "        class_name = idx_to_class[orig_label].lower()\n",
        "        if class_name not in class_list:\n",
        "            continue\n",
        "        new_label = class_list.index(class_name)\n",
        "        images.append(img)\n",
        "        labels.append(new_label)\n",
        "    return torch.stack(images), torch.tensor(labels)\n",
        "\n",
        "train_images_17, train_labels_17 = remap_labels(train_subset_17, new_17_list)\n",
        "test_images_17, test_labels_17 = remap_labels(test_subset_17, new_17_list)\n",
        "\n",
        "train_images_20_small, train_labels_20_small = remap_labels(subset_20_small, first_20_list)\n",
        "\n",
        "train_images_combined = torch.cat([train_images_20_small, train_images_17])\n",
        "train_labels_combined = torch.cat([train_labels_20_small, train_labels_17])\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(train_images_combined, train_labels_combined), batch_size=32, shuffle=True)\n",
        "test_loader_17 = DataLoader(TensorDataset(test_images_17, test_labels_17), batch_size=32, shuffle=False)\n",
        "\n",
        "model = models.resnet18(pretrained=False)\n",
        "model.fc = nn.Linear(model.fc.in_features, 20)\n",
        "model.load_state_dict(torch.load(\"resnet20.pth\"))\n",
        "model.to(device)\n",
        "\n",
        "model.fc = nn.Linear(model.fc.in_features, 37).to(device)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "torch.save(model.state_dict(), \"resnet37_replay.pth\")\n",
        "print(\"Training Completed with Replay. Model saved as resnet37_replay.pth\")\n",
        "\n",
        "test_loader_37 = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "test_subset_20 = Subset(dataset, selected_indices_20)\n",
        "test_images_20, test_labels_20 = remap_labels(test_subset_20, first_20_list)\n",
        "test_loader_20 = DataLoader(TensorDataset(test_images_20, test_labels_20), batch_size=32, shuffle=False)\n",
        "\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "accuracy_37 = evaluate_model(model, test_loader_37)\n",
        "accuracy_20 = evaluate_model(model, test_loader_20)\n",
        "accuracy_17 = evaluate_model(model, test_loader_17)\n",
        "\n",
        "print(f\"Final Test Accuracy on Full 37-class dataset: {accuracy_37:.2f}%\")\n",
        "print(f\"Accuracy on Original 20-class dataset: {accuracy_20:.2f}%\")\n",
        "print(f\"Accuracy on New 17-class dataset: {accuracy_17:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSwrnNKho14y",
        "outputId": "c151967a-8896-47ab-8400-1737e0b0a79e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 105.8541, Accuracy: 33.66%\n",
            "Epoch [2/10], Loss: 74.6432, Accuracy: 49.97%\n",
            "Epoch [3/10], Loss: 69.3605, Accuracy: 52.80%\n",
            "Epoch [4/10], Loss: 65.6420, Accuracy: 54.87%\n",
            "Epoch [5/10], Loss: 62.2031, Accuracy: 58.67%\n",
            "Epoch [6/10], Loss: 61.8955, Accuracy: 58.16%\n",
            "Epoch [7/10], Loss: 61.3004, Accuracy: 58.80%\n",
            "Epoch [8/10], Loss: 57.9077, Accuracy: 60.86%\n",
            "Epoch [9/10], Loss: 57.9202, Accuracy: 61.83%\n",
            "Epoch [10/10], Loss: 57.3594, Accuracy: 62.41%\n",
            "Training Completed with Replay. Model saved as resnet37_replay.pth\n",
            "Final Test Accuracy on Full 37-class dataset: 5.30%\n",
            "Accuracy on Original 20-class dataset: 55.73%\n",
            "Accuracy on New 17-class dataset: 58.41%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zy1cS2EktPSl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}